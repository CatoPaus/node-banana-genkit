{"success":true,"models":[{"id":"googleai/gemini-3-pro-preview","label":"gemini-3-pro-preview","provider":"googleai","description":"googleai/gemini-3-pro-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.5-pro","label":"gemini-2.5-pro","provider":"googleai","description":"googleai/gemini-2.5-pro","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.5-flash","label":"gemini-2.5-flash","provider":"googleai","description":"googleai/gemini-2.5-flash","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.5-flash-lite","label":"gemini-2.5-flash-lite","provider":"googleai","description":"googleai/gemini-2.5-flash-lite","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.0-flash","label":"gemini-2.0-flash","provider":"googleai","description":"googleai/gemini-2.0-flash","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.0-flash-lite","label":"gemini-2.0-flash-lite","provider":"googleai","description":"googleai/gemini-2.0-flash-lite","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemini-2.5-flash-preview-tts","label":"gemini-2.5-flash-preview-tts","provider":"googleai","description":"googleai/gemini-2.5-flash-preview-tts","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":true,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"speechConfig","label":"Speech Config","description":"Speech generation config","type":"object"}],"raw":{"multiturn":false,"media":false,"tools":false,"toolChoice":false,"systemRole":false,"constrained":"no-tools"}}},{"id":"googleai/gemini-2.5-pro-preview-tts","label":"gemini-2.5-pro-preview-tts","provider":"googleai","description":"googleai/gemini-2.5-pro-preview-tts","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":true,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"speechConfig","label":"Speech Config","description":"Speech generation config","type":"object"}],"raw":{"multiturn":false,"media":false,"tools":false,"toolChoice":false,"systemRole":false,"constrained":"no-tools"}}},{"id":"googleai/gemini-3-pro-image-preview","label":"gemini-3-pro-image-preview","provider":"googleai","description":"googleai/gemini-3-pro-image-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"imageConfig","label":"Image Config","type":"object"},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"googleai/gemini-2.5-flash-image-preview","label":"gemini-2.5-flash-image-preview","provider":"googleai","description":"googleai/gemini-2.5-flash-image-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"imageConfig","label":"Image Config","type":"object"},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"googleai/gemini-2.5-flash-image","label":"gemini-2.5-flash-image","provider":"googleai","description":"googleai/gemini-2.5-flash-image","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"imageConfig","label":"Image Config","type":"object"},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"googleai/gemma-3-12b-it","label":"gemma-3-12b-it","provider":"googleai","description":"googleai/gemma-3-12b-it","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":1},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemma-3-1b-it","label":"gemma-3-1b-it","provider":"googleai","description":"googleai/gemma-3-1b-it","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":1},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemma-3-27b-it","label":"gemma-3-27b-it","provider":"googleai","description":"googleai/gemma-3-27b-it","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":1},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemma-3-4b-it","label":"gemma-3-4b-it","provider":"googleai","description":"googleai/gemma-3-4b-it","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":1},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/gemma-3n-e4b-it","label":"gemma-3n-e4b-it","provider":"googleai","description":"googleai/gemma-3n-e4b-it","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":1},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"baseUrl","label":"Base Url","description":"Overrides the plugin-configured or default baseUrl, if specified.","type":"string"},{"key":"apiVersion","label":"Api Version","description":"Overrides the plugin-configured or default apiVersion, if specified.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"codeExecution","label":"Code Execution","description":"Enables the model to generate and run code."},{"key":"contextCache","label":"Context Cache","description":"Context caching allows you to save and reuse precomputed input tokens that you wish to use repeatedly.","type":"boolean"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"responseModalities","label":"Response Modalities","description":"The modalities to be used in response. Only supported for 'gemini-2.0-flash-exp' model at present.","type":"array"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search."},{"key":"fileSearch","label":"File Search","type":"object"},{"key":"urlContext","label":"Url Context","description":"Return grounding metadata from links included in the query"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools","output":["text","json"]}}},{"id":"googleai/veo-3.1-generate-preview","label":"veo-3.1-generate-preview","provider":"googleai","description":"googleai/veo-3.1-generate-preview","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","type":"string"},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output video.","type":"enum","values":["9:16","16:9"]},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"durationSeconds","label":"Duration Seconds","description":"Length of each output video in seconds, between 5 and 8.","type":"number","min":5,"max":8},{"key":"enhancePrompt","label":"Enhance Prompt","description":"Enable or disable the prompt rewriter. Enabled by default.","type":"boolean"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"googleai/veo-3.1-fast-generate-preview","label":"veo-3.1-fast-generate-preview","provider":"googleai","description":"googleai/veo-3.1-fast-generate-preview","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","type":"string"},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output video.","type":"enum","values":["9:16","16:9"]},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"durationSeconds","label":"Duration Seconds","description":"Length of each output video in seconds, between 5 and 8.","type":"number","min":5,"max":8},{"key":"enhancePrompt","label":"Enhance Prompt","description":"Enable or disable the prompt rewriter. Enabled by default.","type":"boolean"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"googleai/veo-3.0-generate-001","label":"veo-3.0-generate-001","provider":"googleai","description":"googleai/veo-3.0-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","type":"string"},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output video.","type":"enum","values":["9:16","16:9"]},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"durationSeconds","label":"Duration Seconds","description":"Length of each output video in seconds, between 5 and 8.","type":"number","min":5,"max":8},{"key":"enhancePrompt","label":"Enhance Prompt","description":"Enable or disable the prompt rewriter. Enabled by default.","type":"boolean"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"googleai/veo-3.0-fast-generate-001","label":"veo-3.0-fast-generate-001","provider":"googleai","description":"googleai/veo-3.0-fast-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","type":"string"},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output video.","type":"enum","values":["9:16","16:9"]},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"durationSeconds","label":"Duration Seconds","description":"Length of each output video in seconds, between 5 and 8.","type":"number","min":5,"max":8},{"key":"enhancePrompt","label":"Enhance Prompt","description":"Enable or disable the prompt rewriter. Enabled by default.","type":"boolean"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"googleai/veo-2.0-generate-001","label":"veo-2.0-generate-001","provider":"googleai","description":"googleai/veo-2.0-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","type":"string"},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output video.","type":"enum","values":["9:16","16:9"]},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"durationSeconds","label":"Duration Seconds","description":"Length of each output video in seconds, between 5 and 8.","type":"number","min":5,"max":8},{"key":"enhancePrompt","label":"Enhance Prompt","description":"Enable or disable the prompt rewriter. Enabled by default.","type":"boolean"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-2.0-generate-001","label":"veo-2.0-generate-001","provider":"vertexai","description":"vertexai/veo-2.0-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.0-generate-001","label":"veo-3.0-generate-001","provider":"vertexai","description":"vertexai/veo-3.0-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.0-fast-generate-001","label":"veo-3.0-fast-generate-001","provider":"vertexai","description":"vertexai/veo-3.0-fast-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.1-fast-generate-001","label":"veo-3.1-fast-generate-001","provider":"vertexai","description":"vertexai/veo-3.1-fast-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.1-fast-generate-preview","label":"veo-3.1-fast-generate-preview","provider":"vertexai","description":"vertexai/veo-3.1-fast-generate-preview","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.1-generate-001","label":"veo-3.1-generate-001","provider":"vertexai","description":"vertexai/veo-3.1-generate-001","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/veo-3.1-generate-preview","label":"veo-3.1-generate-preview","provider":"vertexai","description":"vertexai/veo-3.1-generate-preview","capabilities":{"supportsImageInput":true,"supportsVideo":true,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":true,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"sampleCount","label":"Sample Count","description":"Number of output videos","type":"number"},{"key":"storageUri","label":"Storage Uri","description":"The gcs bucket where to save the generated videos","type":"string"},{"key":"fps","label":"Fps","description":"Frames per second for video generation","type":"number"},{"key":"durationSeconds","label":"Duration Seconds","description":"Duration of the clip for video generation in seconds","type":"number"},{"key":"seed","label":"Seed","description":"The RNG seed. If RNG seed is exactly same for each request with unchanged inputs, the prediction results will be consistent. Otherwise, a random RNG seed will be used each time to produce a different result. If the sample count is greater than 1, random seeds will be used for each sample.","type":"number"},{"key":"aspectRatio","label":"Aspect Ratio","description":"The aspect ratio for the generated video","type":"enum","values":["9:16","16:9"]},{"key":"resolution","label":"Resolution","description":"The resolution for the generated video","type":"enum","values":["720p","1080p"]},{"key":"personGeneration","label":"Person Generation","description":"Specifies the policy for generating persons in videos, including age restrictions","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"pubsubTopic","label":"Pubsub Topic","description":"The pubsub topic to publish the video generation progress to","type":"string"},{"key":"negativePrompt","label":"Negative Prompt","description":"In addition to the text context, negative prompts can be explicitly stated here to help generate the video","type":"string"},{"key":"enhancePrompt","label":"Enhance Prompt","description":"If true, the prompt will be improved before it is used to generate videos. The RNG seed, if provided, will not result in consistent results if prompts are enhanced.","type":"boolean"},{"key":"generateAudio","label":"Generate Audio","description":"If true, audio will be generated along with the video","type":"boolean"},{"key":"compressionQuality","label":"Compression Quality","description":"Compression quality of the generated video","type":"enum","values":["optimized","lossless"]},{"key":"resizeMode","label":"Resize Mode","description":"Veo 3 only. The resize mode that the model uses to resize the video","type":"enum","values":["pad","crop"]},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1. or global","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"],"longRunning":true}}},{"id":"vertexai/imagen-3.0-generate-002","label":"imagen-3.0-generate-002","provider":"vertexai","description":"vertexai/imagen-3.0-generate-002","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-3.0-generate-001","label":"imagen-3.0-generate-001","provider":"vertexai","description":"vertexai/imagen-3.0-generate-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-3.0-capability-001","label":"imagen-3.0-capability-001","provider":"vertexai","description":"vertexai/imagen-3.0-capability-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-3.0-fast-generate-001","label":"imagen-3.0-fast-generate-001","provider":"vertexai","description":"vertexai/imagen-3.0-fast-generate-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-generate-preview-06-06","label":"imagen-4.0-generate-preview-06-06","provider":"vertexai","description":"vertexai/imagen-4.0-generate-preview-06-06","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-ultra-generate-preview-06-06","label":"imagen-4.0-ultra-generate-preview-06-06","provider":"vertexai","description":"vertexai/imagen-4.0-ultra-generate-preview-06-06","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-generate-001","label":"imagen-4.0-generate-001","provider":"vertexai","description":"vertexai/imagen-4.0-generate-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-ultra-generate-001","label":"imagen-4.0-ultra-generate-001","provider":"vertexai","description":"vertexai/imagen-4.0-ultra-generate-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-fast-generate-001","label":"imagen-4.0-fast-generate-001","provider":"vertexai","description":"vertexai/imagen-4.0-fast-generate-001","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/imagen-4.0-upscale-preview","label":"imagen-4.0-upscale-preview","provider":"vertexai","description":"vertexai/imagen-4.0-upscale-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"language","label":"Language","description":"Language of the prompt text.","type":"enum","values":["auto","en","es","hi","ja","ko","pt","zh-TW","zh","zh-CN"]},{"key":"aspectRatio","label":"Aspect Ratio","description":"Desired aspect ratio of the output image.","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"]},{"key":"negativePrompt","label":"Negative Prompt","description":"A description of what to discourage in the generated images. For example: \"animals\" (removes animals), \"blurry\" (makes the image clearer), \"text\" (removes text), or \"cropped\" (removes cropped images).","type":"string"},{"key":"seed","label":"Seed","description":"Controls the randomization of the image generation process. Use the same seed across requests to provide consistency, or change it to introduce variety in the response.","type":"number","min":1,"max":2147483647},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"personGeneration","label":"Person Generation","description":"Control if/how images of people will be generated by the model.","type":"enum","values":["dont_allow","allow_adult","allow_all"]},{"key":"safetySetting","label":"Safety Setting","description":"Adds a filter level to safety filtering.","type":"enum","values":["block_most","block_some","block_few","block_fewest"]},{"key":"addWatermark","label":"Add Watermark","description":"Add an invisible watermark to the generated images.","type":"boolean"},{"key":"storageUri","label":"Storage Uri","description":"Cloud Storage URI to store the generated images.","type":"string"},{"key":"mode","label":"Mode","description":"Mode must be set for upscaling requests.","type":"enum","values":["upscale"]},{"key":"editConfig","label":"Edit Config","type":"object"},{"key":"upscaleConfig","label":"Upscale Config","description":"Configuration for upscaling.","type":"object"},{"key":"upscaleFactor","label":"Upscale Factor","type":"enum","values":["x2","x4"]}],"raw":{"media":true,"multiturn":false,"tools":false,"toolChoice":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/lyria-002","label":"lyria-002","provider":"vertexai","description":"vertexai/lyria-002","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"negativePrompt","label":"Negative Prompt","description":"Optional. A description of what to exclude from the generated audio.","type":"string"},{"key":"seed","label":"Seed","description":"Optional. A seed for deterministic generation. If provided, the model will attempt to produce the same audio given the same prompt and other parameters. Cannot be used with sample_count in the same request.","type":"number"},{"key":"sampleCount","label":"Sample Count","description":"Optional. The number of audio samples to generate. Default is 1 if not specified and seed is not used. Cannot be used with seed in the same request.","type":"number"},{"key":"location","label":"Location","description":"Lyria is only available in global. If you initialize your plugin with a different region, you must set this to global.","type":"string"}],"raw":{"media":true,"multiturn":false,"tools":false,"systemRole":false,"output":["media"]}}},{"id":"vertexai/gemini-3-pro-preview","label":"gemini-3-pro-preview","provider":"vertexai","description":"vertexai/gemini-3-pro-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.5-flash-lite","label":"gemini-2.5-flash-lite","provider":"vertexai","description":"vertexai/gemini-2.5-flash-lite","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.5-pro","label":"gemini-2.5-pro","provider":"vertexai","description":"vertexai/gemini-2.5-pro","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.5-flash","label":"gemini-2.5-flash","provider":"vertexai","description":"vertexai/gemini-2.5-flash","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.0-flash-001","label":"gemini-2.0-flash-001","provider":"vertexai","description":"vertexai/gemini-2.0-flash-001","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.0-flash","label":"gemini-2.0-flash","provider":"vertexai","description":"vertexai/gemini-2.0-flash","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.0-flash-lite","label":"gemini-2.0-flash-lite","provider":"vertexai","description":"vertexai/gemini-2.0-flash-lite","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.0-flash-lite-001","label":"gemini-2.0-flash-lite-001","provider":"vertexai","description":"vertexai/gemini-2.0-flash-lite-001","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":true,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-3-pro-image-preview","label":"gemini-3-pro-image-preview","provider":"vertexai","description":"vertexai/gemini-3-pro-image-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"imageConfig","label":"Image Config","type":"object"},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"vertexai/gemini-2.5-flash-image","label":"gemini-2.5-flash-image","provider":"vertexai","description":"vertexai/gemini-2.5-flash-image","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results. The default value is 1.0.","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse. The default value is 0.95.","type":"number","min":0,"max":1},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"labels","label":"Labels","description":"Key-value labels to attach to the request for cost tracking.","type":"object"},{"key":"location","label":"Location","description":"Google Cloud region e.g. us-central1.","type":"string"},{"key":"safetySettings","label":"Safety Settings","description":"Adjust how likely you are to see responses that could be harmful. Content is blocked based on the probability that it is harmful.","type":"array"},{"key":"vertexRetrieval","label":"Vertex Retrieval","description":"Retrieve from Vertex AI Search data store for grounding generative responses.","type":"object"},{"key":"googleSearchRetrieval","label":"Google Search Retrieval","description":"Retrieve public web data for grounding, powered by Google Search.","type":"object"},{"key":"functionCallingConfig","label":"Function Calling Config","description":"Controls how the model uses the provided tools (function declarations). With AUTO (Default) mode, the model decides whether to generate a natural language response or suggest a function call based on the prompt and context. With ANY, the model is constrained to always predict a function call and guarantee function schema adherence. With NONE, the model is prohibited from making function calls.","type":"object"},{"key":"retrievalConfig","label":"Retrieval Config","type":"object"},{"key":"thinkingConfig","label":"Thinking Config","type":"object"},{"key":"imageConfig","label":"Image Config","type":"object"},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"multiturn":true,"media":true,"tools":true,"toolChoice":true,"systemRole":true,"constrained":"no-tools"}}},{"id":"openai/gpt-4.5","label":"gpt-4.5","provider":"openai","description":"openai/gpt-4.5","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4.5-preview","label":"gpt-4.5-preview","provider":"openai","description":"openai/gpt-4.5-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4o","label":"gpt-4o","provider":"openai","description":"openai/gpt-4o","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4o-2024-05-13","label":"gpt-4o-2024-05-13","provider":"openai","description":"openai/gpt-4o-2024-05-13","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/o1","label":"o1","provider":"openai","description":"openai/o1","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":false,"output":["text","json"]}}},{"id":"openai/o3","label":"o3","provider":"openai","description":"openai/o3","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":false,"output":["text","json"]}}},{"id":"openai/o3-mini","label":"o3-mini","provider":"openai","description":"openai/o3-mini","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":false,"output":["text","json"]}}},{"id":"openai/o4-mini","label":"o4-mini","provider":"openai","description":"openai/o4-mini","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":false,"output":["text","json"]}}},{"id":"openai/gpt-4o-mini","label":"gpt-4o-mini","provider":"openai","description":"openai/gpt-4o-mini","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4o-mini-2024-07-18","label":"gpt-4o-mini-2024-07-18","provider":"openai","description":"openai/gpt-4o-mini-2024-07-18","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-turbo","label":"gpt-4-turbo","provider":"openai","description":"openai/gpt-4-turbo","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-turbo-2024-04-09","label":"gpt-4-turbo-2024-04-09","provider":"openai","description":"openai/gpt-4-turbo-2024-04-09","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-turbo-preview","label":"gpt-4-turbo-preview","provider":"openai","description":"openai/gpt-4-turbo-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-0125-preview","label":"gpt-4-0125-preview","provider":"openai","description":"openai/gpt-4-0125-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-1106-preview","label":"gpt-4-1106-preview","provider":"openai","description":"openai/gpt-4-1106-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"],"constrained":"all"}}},{"id":"openai/gpt-4-vision","label":"gpt-4-vision","provider":"openai","description":"openai/gpt-4-vision","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":false,"media":true,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4-vision-preview","label":"gpt-4-vision-preview","provider":"openai","description":"openai/gpt-4-vision-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":false,"media":true,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4-1106-vision-preview","label":"gpt-4-1106-vision-preview","provider":"openai","description":"openai/gpt-4-1106-vision-preview","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":false,"media":true,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4","label":"gpt-4","provider":"openai","description":"openai/gpt-4","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4-0613","label":"gpt-4-0613","provider":"openai","description":"openai/gpt-4-0613","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4-32k","label":"gpt-4-32k","provider":"openai","description":"openai/gpt-4-32k","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-4-32k-0613","label":"gpt-4-32k-0613","provider":"openai","description":"openai/gpt-4-32k-0613","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-3.5-turbo","label":"gpt-3.5-turbo","provider":"openai","description":"openai/gpt-3.5-turbo","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-3.5-turbo-0125","label":"gpt-3.5-turbo-0125","provider":"openai","description":"openai/gpt-3.5-turbo-0125","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-3.5-turbo-1106","label":"gpt-3.5-turbo-1106","provider":"openai","description":"openai/gpt-3.5-turbo-1106","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":false,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-5","label":"gpt-5","provider":"openai","description":"openai/gpt-5","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-5-mini","label":"gpt-5-mini","provider":"openai","description":"openai/gpt-5-mini","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-5-nano","label":"gpt-5-nano","provider":"openai","description":"openai/gpt-5-nano","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"]}}},{"id":"openai/gpt-5-chat-latest","label":"gpt-5-chat-latest","provider":"openai","description":"openai/gpt-5-chat-latest","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":false,"media":true,"systemRole":true,"output":["text"]}}},{"id":"openai/gpt-5.1","label":"gpt-5.1","provider":"openai","description":"openai/gpt-5.1","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":true,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"version","label":"Version","description":"A specific version of a model family, e.g. `gemini-2.0-flash` for the `googleai` family.","type":"string"},{"key":"temperature","label":"Temperature","type":"number","min":0,"max":2},{"key":"maxOutputTokens","label":"Max Output Tokens","description":"The maximum number of tokens to include in the response.","type":"number"},{"key":"topK","label":"Top K","description":"The maximum number of tokens to consider when sampling.","type":"number"},{"key":"topP","label":"Top P","description":"Decides how many possible words to consider. A higher value means that the model looks at more possible words, even the less likely ones, which makes the generated text more diverse.","type":"number"},{"key":"stopSequences","label":"Stop Sequences","description":"Set of character sequences (up to 5) that will stop output generation.","type":"array"},{"key":"frequencyPenalty","label":"Frequency Penalty","type":"number","min":-2,"max":2},{"key":"logProbs","label":"Log Probs","type":"boolean"},{"key":"presencePenalty","label":"Presence Penalty","type":"number","min":-2,"max":2},{"key":"topLogProbs","label":"Top Log Probs","type":"number","min":0,"max":20},{"key":"store","label":"Store","type":"boolean"}],"raw":{"multiturn":true,"tools":true,"media":true,"systemRole":true,"output":["text","json"]}}},{"id":"openai/tts-1","label":"tts-1","provider":"openai","description":"openai/tts-1","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":true,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"voice","label":"Voice","type":"enum","values":["alloy","echo","fable","onyx","nova","shimmer"]},{"key":"speed","label":"Speed","type":"number","min":0.25,"max":4},{"key":"response_format","label":"Response_format","type":"enum","values":["mp3","opus","aac","flac","wav","pcm"]}],"raw":{"media":false,"output":["media"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/tts-1-hd","label":"tts-1-hd","provider":"openai","description":"openai/tts-1-hd","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":true,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"voice","label":"Voice","type":"enum","values":["alloy","echo","fable","onyx","nova","shimmer"]},{"key":"speed","label":"Speed","type":"number","min":0.25,"max":4},{"key":"response_format","label":"Response_format","type":"enum","values":["mp3","opus","aac","flac","wav","pcm"]}],"raw":{"media":false,"output":["media"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/gpt-4o-mini-tts","label":"gpt-4o-mini-tts","provider":"openai","description":"openai/gpt-4o-mini-tts","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":true,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"voice","label":"Voice","type":"enum","values":["alloy","echo","fable","onyx","nova","shimmer"]},{"key":"response_format","label":"Response_format","type":"enum","values":["mp3","opus","aac","flac","wav","pcm"]}],"raw":{"media":false,"output":["media"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/gpt-4o-transcribe","label":"gpt-4o-transcribe","provider":"openai","description":"openai/gpt-4o-transcribe","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"chunking_strategy","label":"Chunking_strategy"},{"key":"include","label":"Include","type":"array"},{"key":"language","label":"Language","type":"string"},{"key":"timestamp_granularities","label":"Timestamp_granularities","type":"array"},{"key":"response_format","label":"Response_format","type":"enum","values":["json","text","srt","verbose_json","vtt"]}],"raw":{"media":true,"output":["text","json"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/whisper-1","label":"whisper-1","provider":"openai","description":"openai/whisper-1","capabilities":{"supportsImageInput":true,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":true,"supportsGoogleSearch":false,"options":[{"key":"temperature","label":"Temperature","description":"Controls the degree of randomness in token selection. A lower value is good for a more predictable response. A higher value leads to more diverse or unexpected results.","type":"number"},{"key":"chunking_strategy","label":"Chunking_strategy"},{"key":"include","label":"Include","type":"array"},{"key":"language","label":"Language","type":"string"},{"key":"timestamp_granularities","label":"Timestamp_granularities","type":"array"},{"key":"response_format","label":"Response_format","type":"enum","values":["json","text","srt","verbose_json","vtt"]}],"raw":{"media":true,"output":["text","json"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/dall-e-3","label":"dall-e-3","provider":"openai","description":"openai/dall-e-3","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":true,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"size","label":"Size","type":"enum","values":["1024x1024","1792x1024","1024x1792"]},{"key":"style","label":"Style","type":"enum","values":["vivid","natural"]},{"key":"user","label":"User","type":"string"},{"key":"n","label":"N","type":"number","min":1,"max":10},{"key":"quality","label":"Quality","type":"enum","values":["standard","hd"]},{"key":"response_format","label":"Response_format","type":"enum","values":["b64_json","url"]},{"key":"aspectRatio","label":"Aspect Ratio","type":"enum","values":["1:1","9:16","16:9","3:4","4:3"],"description":"The aspect ratio of the generated image."}],"raw":{"media":false,"output":["media"],"multiturn":false,"systemRole":false,"tools":false}}},{"id":"openai/gpt-image-1","label":"gpt-image-1","provider":"openai","description":"openai/gpt-image-1","capabilities":{"supportsImageInput":false,"supportsVideo":false,"supportsAudio":false,"supportsAspectRatio":false,"supportsResolution":false,"supportsCodeExecution":false,"supportsTools":false,"supportsMultimodal":false,"supportsGoogleSearch":false,"options":[{"key":"size","label":"Size","type":"enum","values":["1024x1024","1536x1024","1024x1536","auto"]},{"key":"style","label":"Style","type":"enum","values":["vivid","natural"]},{"key":"user","label":"User","type":"string"},{"key":"n","label":"N","type":"number","min":1,"max":10},{"key":"quality","label":"Quality","type":"enum","values":["low","medium","high"]},{"key":"background","label":"Background","type":"enum","values":["transparent","opaque","auto"]},{"key":"moderation","label":"Moderation","type":"enum","values":["low","auto"]},{"key":"output_compression","label":"Output_compression","type":"number","min":1,"max":100},{"key":"output_format","label":"Output_format","type":"enum","values":["png","jpeg","web"]}],"raw":{"media":false,"output":["media"],"multiturn":false,"systemRole":false,"tools":false}}}]}